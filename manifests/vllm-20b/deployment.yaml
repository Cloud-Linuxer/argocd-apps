apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-gpt-oss-20b
  labels:
    app: vllm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm              # ← 기존 값 유지 (immutable)
  template:
    metadata:
      labels:
        app: vllm            # ← Pod 라벨도 동일
    spec:
      hostIPC: true
      runtimeClassName: nvidia
      containers:
        - name: vllm
          image: vllm/vllm-openai:gptoss
          imagePullPolicy: IfNotPresent
          args:
            - --model
            - openai/gpt-oss-20b
            - --dtype
            - bfloat16
            - --enforce-eager
            - --gpu-memory-utilization
            - "0.85"
            - --max-model-len
            - "8192"
            - --host
            - 0.0.0.0
            - --port
            - "8000"
          env:
            - name: HF_HOME
              value: /root/.cache/huggingface
            - name: VLLM_LOGGING_LEVEL
              value: INFO
            - name: VLLM_USE_V1
              value: "0"
            - name: VLLM_DISABLE_SINKS
              value: "1"
            - name: VLLM_ATTENTION_BACKEND
              value: TORCH_SDPA
          ports:
            - name: http
              containerPort: 8000
          volumeMounts:
            - { name: hf-cache, mountPath: /root/.cache/huggingface }
            - { name: dshm,     mountPath: /dev/shm }
          resources:
            limits:
              nvidia.com/gpu: 1
          readinessProbe:
            httpGet: { path: /v1/models, port: http }
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 3
            failureThreshold: 12
      volumes:
        - name: hf-cache
          hostPath: { path: /home/gpt-oss/.cache/huggingface, type: DirectoryOrCreate }
        - name: dshm
          emptyDir: { medium: Memory, sizeLimit: 8Gi }
